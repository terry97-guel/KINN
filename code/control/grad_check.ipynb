{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"PRIMNET/FINGER\"\n",
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "try: \n",
    "    get_ipython().__class__.__name__\n",
    "    BASEDIR = Path().absolute()\n",
    "except: BASEDIR = Path(__file__).parent\n",
    "\n",
    "sys.path.append(str(BASEDIR))\n",
    "import torch\n",
    "from torch import nn\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "from utils import dataloader\n",
    "from utils.initalize import INITALZE_EVEN_JOINTS\n",
    "from utils.update import  update_primnet, update_fc_primnet, update_pcc_primnet\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import time\n",
    "import json\n",
    "\n",
    "from utils.tools import set_seed, set_wandb, print_log_dict, prefix_dict, average_dict\n",
    "from utils.path_handler import JUPYTER, RUN, DEBUG, get_BASERDIR\n",
    "from utils.args import read_ARGS\n",
    "from utils.logger import CSVLogger,ask_and_make_folder\n",
    "from utils.tools import cast_numpy\n",
    "\n",
    "from configs.template import PRIMNET_ARGS_TEMPLATE, FC_PRIMNET_ARGS_TEMPLATE, PCC_PRIMNET_ARGS_TEMPLATE\n",
    "from model.PRIMNET import PRIMNET\n",
    "from model.FC_PRIMNET import FC_PRIMNET\n",
    "from typing import Union\n",
    "\n",
    "from utils.dataloader import get_dataset, Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Jupyter...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ARGS(MODEL='PRIMNET', EVEN_JOINTS=True, WANDB=True, pname='PRIMNET_v2.1', runname='FINGER', DATASET='FINGER', TPOSE=((0, 0, 0.12),), LOAD_WEIGHTPATH=None, SAVE_PERIOD=1, TEST_PERIOD=1, EVEN_JOINT=True, p_offset_std=0.1, rpy_offset_std=0.01, axis_std=0.1, OUTPUT_NORMALIZE=False, seed=0, hdim=(16, 16), motor_embed_dim=4, lr=0.0015, lrd=0.95, wd=0.0, w_vec=0.001, epochs=500, focus_ratio=0.0, data_ratio=1.0, n_workers=2, batch_size=64, joint_seqs=('F', 'R', 'P', 'R', 'R', 'P', 'R'), marker_num=1, motor_dim=4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASEDIR, RUNMODE = get_BASERDIR(os.getcwd())\n",
    "args = read_ARGS((BASEDIR/'results'/path/\"args.py\").absolute())\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PRIMNET(args=args).to(args.device)\n",
    "\n",
    "model.load_state_dict(torch.load(BASEDIR/'results'/path/\"weights/epoch_500.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_motor(model:PRIMNET, motor_control):     \n",
    "    motor_control = model.normalize(motor_control)\n",
    "    \n",
    "    # Forward\n",
    "    act_embeds = model.ACT_EMBED.layers(motor_control)\n",
    "    q_values = model.FK_LAYER.forward_q(act_embeds)\n",
    "    joint_se3 = model.FK_LAYER.forward_kinematics(q_values)\n",
    "    \n",
    "    return model.t2p(joint_se3, OUTPUT_NORMALIZE=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinematic gradient Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.0052, -0.0211,  0.0104, -0.0003, -0.0076, -0.0046]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motor_control = torch.ones(1,args.motor_dim).to(args.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    act_embeds = model.ACT_EMBED.layers(motor_control)\n",
    "    q_values = model.FK_LAYER.forward_q(act_embeds)\n",
    "\n",
    "q_values = q_values.detach()\n",
    "q_values.requires_grad_(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import autograd, Tensor\n",
    "\n",
    "def forward_kinematics(q_values:Tensor, idx=-1):\n",
    "    assert q_values.ndim == 2\n",
    "    assert q_values.shape[0] == 1\n",
    "    \n",
    "    joint_se3 = model.FK_LAYER.forward_kinematics(q_values)\n",
    "    joint_position = model.t2p(joint_se3, OUTPUT_NORMALIZE=False)\n",
    "\n",
    "    # aux_joints = len(args.joint_seqs)//args.marker_num\n",
    "\n",
    "    # marker_position = []\n",
    "    # for i in range(len(args.joint_seqs)):\n",
    "    #     if (i+1)%aux_joints == 0:\n",
    "    #         joint_position_ = joint_position[:,i]\n",
    "    #         marker_position.append(joint_position_[0])\n",
    "\n",
    "    # return torch.stack(marker_position, dim=0)[prim_idxs]\n",
    "    return joint_position[0,idx,:,0]\n",
    "\n",
    "EE_pos = forward_kinematics(q_values, idx=-1)\n",
    "\n",
    "EE_pos.shape, q_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 7]),\n",
       " tensor([[ 0.0000,  1.5545,  0.4118,  2.1619, -0.1977, -1.0993,  0.0000],\n",
       "         [ 0.0000,  1.0748,  1.3707,  1.0633,  1.6178, -2.5206,  0.0000],\n",
       "         [ 0.0000,  0.2390,  0.1161,  0.2985,  0.2746,  0.1201,  0.0000]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd.functional import jacobian\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "jac_auto = jacobian(partial(forward_kinematics, idx=6), q_values)\n",
    "jac_auto = jac_auto[:,0,:]\n",
    "jac_auto.shape, jac_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motor_control = model.normalize(motor_control)\n",
    "\n",
    "# Forward\n",
    "act_embeds = model.ACT_EMBED.layers(motor_control)\n",
    "q_values = model.FK_LAYER.forward_q(act_embeds)\n",
    "joint_se3 = model.FK_LAYER.forward_kinematics(q_values)\n",
    "\n",
    "joint_position =  model.t2p(joint_se3, OUTPUT_NORMALIZE=False)[0,:,:,0]\n",
    "\n",
    "EE_pos = joint_position[-1]\n",
    "\n",
    "EE_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 3, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.pyart import t2r\n",
    "\n",
    "joint_rotation = t2r(joint_se3[0])\n",
    "joint_rotation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.5523,  0.4091,  2.1767, -0.1897, -1.1088, -0.0000],\n",
       "        [ 0.0000,  1.0695,  1.3713,  1.0501,  1.6179, -2.5162,  0.0000],\n",
       "        [ 0.0000,  0.2355,  0.1179,  0.2864,  0.2686,  0.1241,  0.0000]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.PRIMNET import Fjoint, Tjoint, Rjoint, Pjoint\n",
    "\n",
    "jac_explicit = torch.zeros(3, len(model.FK_LAYER.joints))\n",
    "\n",
    "for idx,joint in enumerate(model.FK_LAYER.joints):\n",
    "    if isinstance(joint, Fjoint):\n",
    "        continue\n",
    "    elif isinstance(joint, Tjoint):\n",
    "        continue\n",
    "    elif isinstance(joint, Rjoint):\n",
    "        pos_diff = EE_pos - joint_position[idx]\n",
    "        jac_explicit[:, idx] = torch.cross(joint_rotation[idx] @ joint.axis.data[:,0], pos_diff)\n",
    "        # print('here')\n",
    "    elif isinstance(joint, Pjoint):\n",
    "        pos_diff = EE_pos - joint_position[idx]\n",
    "        jac_explicit[:,idx] = joint_rotation[idx] @ joint.axis.data[:,0]\n",
    "\n",
    "jac_explicit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoGrad]:0.788793\n",
      "[Explicit]:0.346618\n",
      "Result: [Explicit] is faster than [AutoGrad] by 2.275682 times\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "n = 100\n",
    "\n",
    "start_time = time.time()\n",
    "for _ in range(n):\n",
    "    jac_auto = jacobian(partial(forward_kinematics, idx=6), q_values)\n",
    "    jac_auto = jac_auto[:,0,:]\n",
    "end_time = time.time()\n",
    "\n",
    "autograd_time = end_time-start_time\n",
    "print(\"[AutoGrad]:{:2f}\".format(autograd_time))\n",
    "\n",
    "start_time = time.time()\n",
    "for _ in range(n):\n",
    "    jac_explicit = torch.zeros(3, len(model.FK_LAYER.joints))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        act_embeds = model.ACT_EMBED.layers(motor_control)\n",
    "        q_values = model.FK_LAYER.forward_q(act_embeds)\n",
    "        joint_se3 = model.FK_LAYER.forward_kinematics(q_values)\n",
    "\n",
    "        joint_position =  model.t2p(joint_se3, OUTPUT_NORMALIZE=False)[0,:,:,0]\n",
    "\n",
    "        EE_pos = joint_position[-1]\n",
    "\n",
    "    for idx,joint in enumerate(model.FK_LAYER.joints):\n",
    "        if isinstance(joint, Fjoint):\n",
    "            continue\n",
    "        elif isinstance(joint, Tjoint):\n",
    "            continue\n",
    "        elif isinstance(joint, Rjoint):\n",
    "            pos_diff = EE_pos - joint_position[idx]\n",
    "            jac_explicit[:, idx] = torch.cross(joint_rotation[idx] @ joint.axis.data[:,0], pos_diff)\n",
    "            # print('here')\n",
    "        elif isinstance(joint, Pjoint):\n",
    "            pos_diff = EE_pos - joint_position[idx]\n",
    "            jac_explicit[:,idx] = joint_rotation[idx] @ joint.axis.data[:,0]\n",
    "end_time = time.time()\n",
    "explicit_time = end_time-start_time\n",
    "print(\"[Explicit]:{:2f}\".format(explicit_time))\n",
    "\n",
    "print(\"Result: [Explicit] is faster than [AutoGrad] by {:2f} times\".format(autograd_time/explicit_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: [without_grad] is faster than [with_grad] by 1.373967 times\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "\n",
    "start_time = time.time()\n",
    "for _ in range(n):\n",
    "    forward_kinematics(q_values, idx=6)\n",
    "end_time = time.time()\n",
    "\n",
    "with_grad_time = end_time-start_time\n",
    "\n",
    "start_time = time.time()\n",
    "for _ in range(n):\n",
    "    with torch.no_grad():\n",
    "        forward_kinematics(q_values, idx=6)\n",
    "end_time = time.time()\n",
    "without_grad_time = end_time-start_time\n",
    "\n",
    "print(\"Result: [without_grad] is faster than [with_grad] by {:2f} times\".format(with_grad_time/without_grad_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
